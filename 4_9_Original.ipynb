{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcDQ6hyy2Kd1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import pprint\n",
    "import string\n",
    "# import gensim\n",
    "# import gensim.corpora as corpora\n",
    "# from gensim.models import CoherenceModel\n",
    "# from gensim.utils import simple_preprocess\n",
    "# from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DUTYgC_2KeM"
   },
   "outputs": [],
   "source": [
    "closed_class_stop_words = ['a', 'the', 'an', 'and', 'or', 'but', 'about', 'above', 'after', 'along', 'amid', 'among', \\\n",
    "                           'as', 'at', 'by', 'for', 'from', 'in', 'into', 'like', 'minus', 'near', 'of', 'off', 'on', \\\n",
    "                           'onto', 'out', 'over', 'past', 'per', 'plus', 'since', 'till', 'to', 'under', 'until', 'up', \\\n",
    "                           'via', 'vs', 'with', 'that', 'can', 'cannot', 'could', 'may', 'might', 'must', \\\n",
    "                           'need', 'ought', 'shall', 'should', 'will', 'would', 'have', 'had', 'has', 'having', 'be', \\\n",
    "                           'is', 'am', 'are', 'was', 'were', 'being', 'been', 'get', 'gets', 'got', 'gotten', \\\n",
    "                           'getting', 'seem', 'seeming', 'seems', 'seemed', \\\n",
    "                           'enough', 'both', 'all', 'your' 'those', 'this', 'these', \\\n",
    "                           'their', 'the', 'that', 'some', 'our', 'no', 'neither', 'my', \\\n",
    "                           'its', 'his' 'her', 'every', 'either', 'each', 'any', 'another', \\\n",
    "                           'an', 'a', 'just', 'mere', 'such', 'merely' 'right', 'no', 'not', \\\n",
    "                           'only', 'sheer', 'even', 'especially', 'namely', 'as', 'more', \\\n",
    "                           'most', 'less' 'least', 'so', 'enough', 'too', 'pretty', 'quite', \\\n",
    "                           'rather', 'somewhat', 'sufficiently' 'same', 'different', 'such', \\\n",
    "                           'when', 'why', 'where', 'how', 'what', 'who', 'whom', 'which', \\\n",
    "                           'whether', 'why', 'whose', 'if', 'anybody', 'anyone', 'anyplace', \\\n",
    "                           'anything', 'anytime' 'anywhere', 'everybody', 'everyday', \\\n",
    "                           'everyone', 'everyplace', 'everything' 'everywhere', 'whatever', \\\n",
    "                           'whenever', 'whereever', 'whichever', 'whoever', 'whomever' 'he', \\\n",
    "                           'him', 'his', 'her', 'she', 'it', 'they', 'them', 'its', 'their', 'theirs', \\\n",
    "                           'you', 'your', 'yours', 'me', 'my', 'mine', 'I', 'we', 'us', 'much', 'and/or']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eN4V5yj2Kee"
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZNgG1M62Kep"
   },
   "outputs": [],
   "source": [
    "file1 = open('Glossary/FREQUENT_LIST.txt')\n",
    "file2 = open('Glossary/BIOLOGY_OF.txt')\n",
    "file3 = open('Glossary/ECOLOGY_OF.txt')\n",
    "file4 = open('Glossary/EARTH_OF.txt')\n",
    "file5 = open('Glossary/PHYSICS_OF.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pB5XD1Ll2Kev"
   },
   "outputs": [],
   "source": [
    "def most_common(file):\n",
    "    common = []\n",
    "    for msg in file:\n",
    "        if msg != '\\n':\n",
    "            word = word_tokenize(msg)\n",
    "            word = word[0].lower()\n",
    "            word = wordnet_lemmatizer.lemmatize(word)\n",
    "            common.append(word)\n",
    "    return common\n",
    "common = most_common(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZq4tUtx2KfD"
   },
   "outputs": [],
   "source": [
    "def bio_dictionary(file):\n",
    "    dictionary = {}\n",
    "    for msg in file:\n",
    "        if msg != '\\n':\n",
    "            #nextline = file.next()\n",
    "            phrase = word_tokenize(msg)\n",
    "            # print(phrase)\n",
    "            for x in phrase:\n",
    "                x = x.lower()\n",
    "                x = wordnet_lemmatizer.lemmatize(x)\n",
    "                if x[0] not in string.punctuation:\n",
    "                    if x[0] in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                        if x not in closed_class_stop_words:\n",
    "                            if x not in common:\n",
    "                                if x not in dictionary and len(x) > 1:\n",
    "                                    dictionary[x] = 0.0\n",
    "                                # print()\n",
    "    \n",
    "   \n",
    "    print(\"THE LENGTH OF BIO DICTIONARY IS \",len(dictionary))\n",
    "    return dictionary\n",
    "\n",
    "def eco_dictionary(file):\n",
    "    dictionary = {}\n",
    "    for msg in file:\n",
    "        if msg != '\\n':\n",
    "            #nextline = file.next()\n",
    "            phrase = word_tokenize(msg)\n",
    "            # print(phrase)\n",
    "            for x in phrase:\n",
    "                x = x.lower()\n",
    "                x = wordnet_lemmatizer.lemmatize(x)\n",
    "                if x[0] not in string.punctuation:\n",
    "                    if x[0] in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                        if x not in closed_class_stop_words:\n",
    "                            if x not in common:\n",
    "                                if x not in dictionary and len(x) > 1:\n",
    "                                    dictionary[x] = 0.0\n",
    "                                # print()\n",
    "   \n",
    "    \n",
    "    print(\"THE LENGTH OF ECO DICTIONARY IS \",len(dictionary))\n",
    "    return dictionary\n",
    "\n",
    "def earth_dictionary(file):\n",
    "    dictionary = {}\n",
    "    for msg in file:\n",
    "        if msg != '\\n':\n",
    "            # nextline = file.next()\n",
    "            phrase = word_tokenize(msg)\n",
    "            # print(phrase)\n",
    "            for x in phrase:\n",
    "                x = x.lower()\n",
    "                x = wordnet_lemmatizer.lemmatize(x)\n",
    "                if x[0] not in string.punctuation:\n",
    "                    if x[0] in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                        if x not in closed_class_stop_words:\n",
    "                            if x not in common:\n",
    "                                if x not in dictionary and len(x) > 1:\n",
    "                                    dictionary[x] = 0.0\n",
    "                                    # print()\n",
    "     \n",
    "    print(\"THE LENGTH OF EARTH DICTIONARY IS \", len(dictionary))\n",
    "    return dictionary\n",
    "\n",
    "def physics_dictionary(file):\n",
    "    dictionary = {}\n",
    "    for msg in file:\n",
    "        if msg != '\\n':\n",
    "            # nextline = file.next()\n",
    "            phrase = word_tokenize(msg)\n",
    "            # print(phrase)\n",
    "            for x in phrase:\n",
    "                x = x.lower()\n",
    "                x = wordnet_lemmatizer.lemmatize(x)\n",
    "                if x[0] not in string.punctuation:\n",
    "                    if x[0] in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                        if x not in closed_class_stop_words:\n",
    "                            if x not in common:\n",
    "                                if x not in dictionary and len(x) > 1:\n",
    "                                    dictionary[x] = 0.0\n",
    "                                    # print()\n",
    "    \n",
    "   \n",
    "    print(\"THE LENGTH OF PHYSICS DICTIONARY IS \", len(dictionary))\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXldcIhL2KfK",
    "outputId": "e614b673-ec24-4c3b-bacb-a703a587ce2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE LENGTH OF BIO DICTIONARY IS  4997\n",
      "THE LENGTH OF ECO DICTIONARY IS  5542\n",
      "THE LENGTH OF EARTH DICTIONARY IS  8041\n",
      "THE LENGTH OF PHYSICS DICTIONARY IS  2770\n"
     ]
    }
   ],
   "source": [
    "look1 = bio_dictionary(file2)\n",
    "look2 = eco_dictionary(file3)\n",
    "look3 = earth_dictionary(file4)\n",
    "look4 = physics_dictionary(file5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2jOQSYC2Kgh"
   },
   "outputs": [],
   "source": [
    "for file in [file1,file2,file3,file4,file5]:\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1yQWcVu2Kgp"
   },
   "outputs": [],
   "source": [
    "file_4 = open('train_PURE/NS_LS_4_PURE.txt')\n",
    "file_6 = open('train_PURE/NS_LS_6_PURE.txt')\n",
    "file_8 = open('train_PURE/NS_LS_8_PURE.txt')\n",
    "file_12 = open('train_PURE/NS_LS_12_PURE.txt')\n",
    "file_16 = open('train_PURE/SA_LS_PURE.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kha74wLc2Kgz"
   },
   "outputs": [],
   "source": [
    "def tailor_version():\n",
    "    FILES = [file_4, file_6, file_8, file_12, file_16]\n",
    "    grades = [4,6,8,12,16]\n",
    "    grade_words = []\n",
    "    for i in range(len(FILES)):\n",
    "        bio_words = []\n",
    "        eco_words = []\n",
    "        earth_words = []\n",
    "        physics_words = []\n",
    "        for msg in FILES[i]:\n",
    "            if msg != '\\n':\n",
    "                x = word_tokenize(msg)\n",
    "                for word in x:\n",
    "                    if len(word) >= 2:\n",
    "                        word = word.lower()\n",
    "                        word = wordnet_lemmatizer.lemmatize(word)\n",
    "                        if word[0] in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                            if word not in closed_class_stop_words:\n",
    "                                if word in look1.keys():\n",
    "                                    look1[word] += 1.0\n",
    "                                    if word not in bio_words:\n",
    "                                        bio_words.append(word)\n",
    "                                if word in look2.keys():\n",
    "                                    look2[word] += 1.0\n",
    "                                    if word not in eco_words:\n",
    "                                        eco_words.append(word)\n",
    "                                if word in look3.keys():\n",
    "                                    look3[word] += 1.0\n",
    "                                    if word not in earth_words:\n",
    "                                        earth_words.append(word)\n",
    "                                if word in look4.keys():\n",
    "                                    look4[word] += 1.0\n",
    "                                    if word not in physics_words:\n",
    "                                        physics_words.append(word)\n",
    "        FILES[i].close()\n",
    "        print(\"SIZE OF BIO WORDS FOR \", grades[i], \" is \", len(bio_words))\n",
    "        print(\"SIZE OF ECO WORDS FOR \", grades[i], \" is \", len(eco_words))\n",
    "        print(\"SIZE OF EARTH WORDS FOR \", grades[i], \" is \", len(earth_words))\n",
    "        print(\"SIZE OF PHYSICS WORDS FOR \", grades[i], \" is \", len(physics_words))\n",
    "        combine_words = []\n",
    "        for x in bio_words:\n",
    "            combine_words.append(x)\n",
    "        for x in eco_words:\n",
    "            if x not in combine_words:\n",
    "                combine_words.append(x)\n",
    "        for x in earth_words:\n",
    "            if x not in combine_words:\n",
    "                combine_words.append(x)\n",
    "        for x in physics_words:\n",
    "            if x not in combine_words:\n",
    "                combine_words.append(x)\n",
    "        if \"n't\" in combine_words:\n",
    "            combine_words.remove(\"n't\")\n",
    "        grade_words.append(combine_words)\n",
    "        print(\"SIZE OF COMBINE WORDS IS \", len(combine_words))\n",
    "        print('\\n')\n",
    "\n",
    "    primary = []\n",
    "    gap_4_6 = []\n",
    "    for term in grade_words[1]:\n",
    "        if term not in grade_words[0]:\n",
    "            gap_4_6.append(term)\n",
    "        else:\n",
    "            primary.append(term)\n",
    "\n",
    "    gap_8_12 = []\n",
    "    gap_6_8 = []\n",
    "    gap_12_14 = []\n",
    "    for term in grade_words[2]:\n",
    "        if term not in grade_words[0]:\n",
    "            if term not in grade_words[1]:\n",
    "                gap_6_8.append(term)\n",
    "\n",
    "    for term in grade_words[3]:\n",
    "        if term not in grade_words[2]:\n",
    "            if term not in grade_words[1]:\n",
    "                if term not in grade_words[0]:\n",
    "                    gap_8_12.append(term)\n",
    "\n",
    "    for term in grade_words[4]:\n",
    "        if ((term in look1) and (look1[term] >= 3)) or ((term in look2) and (look2[term] >= 3)) or ((term in look3) and (look3[term] >= 3))or ((term in look4) and (look4[term] >= 3)):\n",
    "            if term not in grade_words[0]:\n",
    "                if term not in grade_words[1]:\n",
    "                    if term not in grade_words[2]:\n",
    "                        if term not in grade_words[3]:\n",
    "                            gap_12_14.append(term)\n",
    "\n",
    "    final_list = [primary,gap_4_6,gap_6_8,gap_8_12,gap_12_14]\n",
    "\n",
    "    print(\"THIS IS PRIMARY\")\n",
    "    print(primary[:10])\n",
    "    print(len(primary))\n",
    "    print('\\n')\n",
    "    print(\"THIS IS GAP_4_6\")\n",
    "    print(gap_4_6[:10])\n",
    "    print(len(gap_4_6))\n",
    "    print('\\n')\n",
    "    print(\"THIS IS GAP_6_8\")\n",
    "    print(gap_6_8[:10])\n",
    "    print(len(gap_6_8))\n",
    "    print('\\n')\n",
    "    print(\"THIS IS GAP_8_12\")\n",
    "    print(gap_8_12[:10])\n",
    "    print(len(gap_8_12))\n",
    "    print('\\n')\n",
    "    print(\"THIS IS COLLEGE_LIST\")\n",
    "    print(gap_12_14[:10])\n",
    "    print(len(gap_12_14))\n",
    "    print('\\n')\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnUWGoJD2Kg-",
    "outputId": "34cc333a-0b13-4188-c994-a939ad0a8ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE OF BIO WORDS FOR  4  is  469\n",
      "SIZE OF ECO WORDS FOR  4  is  649\n",
      "SIZE OF EARTH WORDS FOR  4  is  751\n",
      "SIZE OF PHYSICS WORDS FOR  4  is  387\n",
      "SIZE OF COMBINE WORDS IS  1274\n",
      "\n",
      "\n",
      "SIZE OF BIO WORDS FOR  6  is  660\n",
      "SIZE OF ECO WORDS FOR  6  is  923\n",
      "SIZE OF EARTH WORDS FOR  6  is  1036\n",
      "SIZE OF PHYSICS WORDS FOR  6  is  571\n",
      "SIZE OF COMBINE WORDS IS  1775\n",
      "\n",
      "\n",
      "SIZE OF BIO WORDS FOR  8  is  821\n",
      "SIZE OF ECO WORDS FOR  8  is  1098\n",
      "SIZE OF EARTH WORDS FOR  8  is  1236\n",
      "SIZE OF PHYSICS WORDS FOR  8  is  675\n",
      "SIZE OF COMBINE WORDS IS  2158\n",
      "\n",
      "\n",
      "SIZE OF BIO WORDS FOR  12  is  1000\n",
      "SIZE OF ECO WORDS FOR  12  is  1322\n",
      "SIZE OF EARTH WORDS FOR  12  is  1508\n",
      "SIZE OF PHYSICS WORDS FOR  12  is  790\n",
      "SIZE OF COMBINE WORDS IS  2611\n",
      "\n",
      "\n",
      "SIZE OF BIO WORDS FOR  16  is  1448\n",
      "SIZE OF ECO WORDS FOR  16  is  1641\n",
      "SIZE OF EARTH WORDS FOR  16  is  1782\n",
      "SIZE OF PHYSICS WORDS FOR  16  is  1074\n",
      "SIZE OF COMBINE WORDS IS  3476\n",
      "\n",
      "\n",
      "THIS IS PRIMARY\n",
      "['grape', 'international', 'genetics', 'competitive', 'producer', 'breeding', 'calorie', 'nutrition', 'signature', 'vaccine']\n",
      "1247\n",
      "\n",
      "\n",
      "THIS IS GAP_4_6\n",
      "['niche', 'editing', 'intestine', 'resistance', 'next-generation', 'content', 'pregnancy', 'limiting', 'denisovan', 'sequence']\n",
      "528\n",
      "\n",
      "\n",
      "THIS IS GAP_6_8\n",
      "['floral', 'therapy', 'hiv', 'zygote', 'embryo', 'enzyme', 'targeting', 'fungi', 'bacterial', 'allergen']\n",
      "430\n",
      "\n",
      "\n",
      "THIS IS GAP_8_12\n",
      "['microbiology', 'immunology', 'defective', 'progeny', 'palindromic', 'hybridization', 'identical', 'intestinal', 'complement', 'fatigue']\n",
      "535\n",
      "\n",
      "\n",
      "THIS IS COLLEGE_LIST\n",
      "['intrinsic', 'continuous', 'rigor', 'dogma', 'physiology', 'metabolism', 'carbohydrate', 'gram', 'insulin', 'glucose']\n",
      "552\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LEVEL_SCI = tailor_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5t_gK_g2KhH",
    "outputId": "34e1c94c-a8ed-4283-ac6f-a9482c925e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3292\n"
     ]
    }
   ],
   "source": [
    "SCI = LEVEL_SCI[0]+LEVEL_SCI[1]+LEVEL_SCI[2]+LEVEL_SCI[3]+LEVEL_SCI[4]\n",
    "print(len(SCI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7AdoU8o2KhS"
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWhVs9BX2Khb"
   },
   "outputs": [],
   "source": [
    "def TF_IDF(V,L):\n",
    "    total_sentence = len(V)\n",
    "    #print(len(V))\n",
    "    if (len(V) == 0):\n",
    "        total_AWL = 0\n",
    "    else:\n",
    "        total_AWL = len(V[0])\n",
    "    #print(total_AWL)\n",
    "    sum = {}\n",
    "    TFIDF = []\n",
    "    TFIDF_TOTAL = []\n",
    "    for i in range(total_AWL):\n",
    "        sum[i] = 0.0\n",
    "        #print(type(sum[i]))\n",
    "\n",
    "    for i in range(len(V)):\n",
    "        for j in range(len(V[i])):\n",
    "            #print(V[i][j])\n",
    "            if V[i][j] != 0.0:\n",
    "                sum[j] += 1.0\n",
    "\n",
    "    IDF = []\n",
    "\n",
    "    for i in range(total_AWL):\n",
    "        if sum[i] == 0:\n",
    "            idf = 0.0\n",
    "        else:\n",
    "            idf = float(math.log(float(total_sentence)/sum[i]))\n",
    "            #print(idf)\n",
    "        IDF.append(idf)\n",
    "\n",
    "\n",
    "    for i in range(total_sentence):\n",
    "        for j in range(total_AWL):\n",
    "            #print(float(V[i][j]))\n",
    "            TF = float(V[i][j]/float(L[i]))\n",
    "\n",
    "            TFIDF.append(float(TF*IDF[j]))\n",
    "\n",
    "\n",
    "        TFIDF_TOTAL.append(TFIDF)\n",
    "\n",
    "        TFIDF = []\n",
    "\n",
    "    return TFIDF_TOTAL\n",
    "\n",
    "\n",
    "def read_pure(file):\n",
    "    collection_vectors_SCI = []\n",
    "    collection_lengths = []\n",
    "    article = 0\n",
    "    collection_total_SCI = []\n",
    "    for msg in file:\n",
    "        if msg[:4] == '.LS.':\n",
    "            if article >= 1:\n",
    "                m = np.mean(TF_IDF(collection_vectors_SCI, collection_lengths),axis = 0)\n",
    "                collection_total_SCI.append(m)\n",
    "                collection_vectors_SCI = []\n",
    "                collection_lengths = []\n",
    "\n",
    "            article += 1\n",
    "\n",
    "        else:\n",
    "            x = word_tokenize(msg)\n",
    "            length = len(x)\n",
    "            if length > 0:\n",
    "                new_length = []\n",
    "                vector_SCI = {}\n",
    "\n",
    "                for b in SCI:\n",
    "                    vector_SCI[b] = 0.0\n",
    "                for i in range(length):\n",
    "                    if x[i] not in closed_class_stop_words:\n",
    "                        new_length.append(x[i])\n",
    "\n",
    "                        m = wordnet_lemmatizer.lemmatize(x[i])\n",
    "                        if m in SCI:\n",
    "                            if m in LEVEL_SCI[0]:\n",
    "                                vector_SCI[m] += 2.0\n",
    "                            elif m in LEVEL_SCI[1]:\n",
    "                                vector_SCI[m] += 4.0\n",
    "                            elif m in LEVEL_SCI[2]:\n",
    "                                vector_SCI[m] += 6.0\n",
    "                            elif m in LEVEL_SCI[3]:\n",
    "                                vector_SCI[m] += 8.0\n",
    "                            else:\n",
    "                                vector_SCI[m] += 10.0\n",
    "                collection_lengths.append(len(new_length))\n",
    "                collections_SCI = []\n",
    "                for b in vector_SCI:\n",
    "                    collections_SCI.append(float(vector_SCI[b]))\n",
    "                collection_vectors_SCI.append(collections_SCI)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    mean_SCI = np.mean(TF_IDF(collection_vectors_SCI,collection_lengths),axis = 0)\n",
    "\n",
    "    collection_total_SCI.append(mean_SCI)\n",
    "    \n",
    "    SCI_TERMS = np.mean(collection_total_SCI,axis = 0)\n",
    "\n",
    "    print('READ_PURE')\n",
    "    return collection_total_SCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rN_2VcAN2Khh"
   },
   "outputs": [],
   "source": [
    "def prepare_training():\n",
    "    file_4 = open('train_PURE/NS_LS_4_PURE.txt')\n",
    "    file_6 = open('train_PURE/NS_LS_6_PURE.txt')\n",
    "    file_8 = open('train_PURE/NS_LS_8_PURE.txt')\n",
    "    file_12 = open('train_PURE/NS_LS_12_PURE.txt')\n",
    "    file_16 = open('train_PURE/SA_LS_PURE.txt')\n",
    "    vectors_4 = read_pure(file_4)\n",
    "    vectors_6 = read_pure(file_6)\n",
    "    vectors_8 = read_pure(file_8)\n",
    "    vectors_12 = read_pure(file_12)\n",
    "    vectors_16 = read_pure(file_16)\n",
    "    lis = [vectors_4,vectors_6,vectors_8,vectors_12,vectors_16]\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqtVF50w2Khn",
    "outputId": "cca3b867-bbb4-4533-dee4-1ad731ef104b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ_PURE\n",
      "READ_PURE\n",
      "READ_PURE\n",
      "READ_PURE\n",
      "READ_PURE\n"
     ]
    }
   ],
   "source": [
    "training_lis = prepare_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-VsXojq2Kh1"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(list_articles,list_lables):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    college_count = 0\n",
    "    for x in list_articles:\n",
    "        print(len(x))\n",
    "    for i in range(300):\n",
    "        \n",
    "        #append grade 4\n",
    "        X_train.append(list_articles[0][i])\n",
    "        y_train.append(list_lables[0])\n",
    "        #append grade 6\n",
    "        X_train.append(list_articles[1][i])\n",
    "        y_train.append(list_lables[1])\n",
    "        #append grade 8\n",
    "        X_train.append(list_articles[2][i])\n",
    "        y_train.append(list_lables[2])\n",
    "        #append grade 12\n",
    "        X_train.append(list_articles[3][i])\n",
    "        y_train.append(list_lables[3])\n",
    "        if ((i+1) // 3) != 0 and college_count < 200:\n",
    "            #append college\n",
    "            X_train.append(list_articles[4][college_count])\n",
    "            y_train.append(list_lables[4])\n",
    "            college_count += 1\n",
    "    n = len(y_train)\n",
    "    print(n)\n",
    "    y_train = np.array(y_train)\n",
    "    y_train = y_train.reshape((n,))\n",
    "    return (np.asarray(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEdPp6io2Kh-",
    "outputId": "7b0a198c-0204-4eb4-8d64-7855bd878659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "200\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train = prepare_dataset(training_lis,[4,6,8,12,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbnEcVun2KiH",
    "outputId": "ed43547f-8453-4053-d66a-2c2176e69c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  6  8 12  4  6  8 12  4  6  8 12 16  4  6  8 12 16  4  6  8 12 16  4\n",
      "  6  8 12 16  4  6  8 12 16  4  6  8 12 16  4  6  8 12 16  4  6  8 12 16\n",
      "  4  6  8 12 16  4  6  8 12 16  4  6  8 12 16  4  6  8 12 16  4  6  8 12\n",
      " 16  4  6  8 12 16  4  6  8 12 16  4  6  8 12 16  4  6  8 12 16  4  6  8\n",
      " 12 16  4  6]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_UUTvPg2KiT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def my_kernel(X, Y):\n",
    "    return cosine_similarity(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUTF00qd2Kif"
   },
   "outputs": [],
   "source": [
    "def cross_validation(k_fold,clf,X,y,max_feature,ngram_range):\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    \n",
    "    for train, test in k_fold.split(X):\n",
    "       \n",
    "        clf.fit(X[train], y[train])\n",
    "        y_pred = clf.predict(X[test])\n",
    "        y_true = y[test]\n",
    "        accuracy_list.append(accuracy_score(y_true, y_pred))\n",
    "        precision_list.append(precision_score(y_true, y_pred,y_pred,average = 'macro'))\n",
    "        recall_list.append(recall_score(y_true, y_pred,average = 'macro'))\n",
    "    result = []    \n",
    "    for score in [accuracy_list,precision_list,recall_list]:\n",
    "        result.append(np.mean(score))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQgACGkk2Kim"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "def train_models(train_X, train_y,max_feature,ngram_range):\n",
    "    k_fold = KFold(n_splits=5,shuffle = False)\n",
    "    results = []\n",
    "    models = []\n",
    "    models.append(svm.SVC(C=1.0, kernel=my_kernel, degree=3))\n",
    "    models.append(BernoulliNB(alpha=0.3, binarize=0.0))\n",
    "    models.append(BernoulliNB(alpha=0.5, binarize=0.0))\n",
    "    models.append(BernoulliNB(alpha=0.4, binarize=0.0))\n",
    "    models_name = ['svm.SVC(C=1, kernel=my_kernel(cos), degree=3)','BernoulliNB(alpha=0.3, binarize=0.0)','BernoulliNB(alpha=0.5, binarize=0.0)','BernoulliNB(alpha=0.4, binarize=0.0)']\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        print(i)\n",
    "        lis = cross_validation(k_fold,models[i],train_X, train_y,max_feature,ngram_range)\n",
    "        results.append([models_name[i],lis[0],lis[1],lis[2]])\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.columns = ['MODEL', 'Accuracy','Precision','Recall']\n",
    "    return results_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yn-I9ucW2Kiu",
    "outputId": "e0310095-8167-427b-addd-3984920b0edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongx\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm.SVC(C=1, kernel=my_kernel(cos), degree=3)</td>\n",
       "      <td>0.562143</td>\n",
       "      <td>0.562143</td>\n",
       "      <td>0.547675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB(alpha=0.3, binarize=0.0)</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.595473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB(alpha=0.5, binarize=0.0)</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.582590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB(alpha=0.4, binarize=0.0)</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.588857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           MODEL  Accuracy  Precision  \\\n",
       "0  svm.SVC(C=1, kernel=my_kernel(cos), degree=3)  0.562143   0.562143   \n",
       "1           BernoulliNB(alpha=0.3, binarize=0.0)  0.614286   0.614286   \n",
       "2           BernoulliNB(alpha=0.5, binarize=0.0)  0.600000   0.600000   \n",
       "3           BernoulliNB(alpha=0.4, binarize=0.0)  0.606429   0.606429   \n",
       "\n",
       "     Recall  \n",
       "0  0.547675  \n",
       "1  0.595473  \n",
       "2  0.582590  \n",
       "3  0.588857  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop_word \n",
    "train_models(X_train, y_train,1000,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L8n4G4qg2Ki6",
    "outputId": "5c8b088f-611a-4584-a285-24de66b8d8b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongx\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm.SVC(C=1, kernel=my_kernel(cos), degree=3)</td>\n",
       "      <td>0.562143</td>\n",
       "      <td>0.562143</td>\n",
       "      <td>0.547675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB(alpha=0.3, binarize=0.0)</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.595473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB(alpha=0.5, binarize=0.0)</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.582590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB(alpha=0.4, binarize=0.0)</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.588857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           MODEL  Accuracy  Precision  \\\n",
       "0  svm.SVC(C=1, kernel=my_kernel(cos), degree=3)  0.562143   0.562143   \n",
       "1           BernoulliNB(alpha=0.3, binarize=0.0)  0.614286   0.614286   \n",
       "2           BernoulliNB(alpha=0.5, binarize=0.0)  0.600000   0.600000   \n",
       "3           BernoulliNB(alpha=0.4, binarize=0.0)  0.606429   0.606429   \n",
       "\n",
       "     Recall  \n",
       "0  0.547675  \n",
       "1  0.595473  \n",
       "2  0.582590  \n",
       "3  0.588857  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop_word \n",
    "train_models(X_train, y_train,1000,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlpTETLt2KjB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongx\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm.SVC(C=1, kernel=my_kernel(cos), degree=3)</td>\n",
       "      <td>0.562143</td>\n",
       "      <td>0.562143</td>\n",
       "      <td>0.547675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB(alpha=0.3, binarize=0.0)</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.595473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB(alpha=0.5, binarize=0.0)</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.582590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB(alpha=0.4, binarize=0.0)</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.588857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           MODEL  Accuracy  Precision  \\\n",
       "0  svm.SVC(C=1, kernel=my_kernel(cos), degree=3)  0.562143   0.562143   \n",
       "1           BernoulliNB(alpha=0.3, binarize=0.0)  0.614286   0.614286   \n",
       "2           BernoulliNB(alpha=0.5, binarize=0.0)  0.600000   0.600000   \n",
       "3           BernoulliNB(alpha=0.4, binarize=0.0)  0.606429   0.606429   \n",
       "\n",
       "     Recall  \n",
       "0  0.547675  \n",
       "1  0.595473  \n",
       "2  0.582590  \n",
       "3  0.588857  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop_word\n",
    "train_models(X_train, y_train,1000,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongx\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm.SVC(C=1, kernel=my_kernel(cos), degree=3)</td>\n",
       "      <td>0.562143</td>\n",
       "      <td>0.562143</td>\n",
       "      <td>0.547675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB(alpha=0.3, binarize=0.0)</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.595473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB(alpha=0.5, binarize=0.0)</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.582590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB(alpha=0.4, binarize=0.0)</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.606429</td>\n",
       "      <td>0.588857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           MODEL  Accuracy  Precision  \\\n",
       "0  svm.SVC(C=1, kernel=my_kernel(cos), degree=3)  0.562143   0.562143   \n",
       "1           BernoulliNB(alpha=0.3, binarize=0.0)  0.614286   0.614286   \n",
       "2           BernoulliNB(alpha=0.5, binarize=0.0)  0.600000   0.600000   \n",
       "3           BernoulliNB(alpha=0.4, binarize=0.0)  0.606429   0.606429   \n",
       "\n",
       "     Recall  \n",
       "0  0.547675  \n",
       "1  0.595473  \n",
       "2  0.582590  \n",
       "3  0.588857  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop_word\n",
    "train_models(X_train, y_train,1000,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def train_models(train_X_o, train_y_o,max_feature,ngram_range):\n",
    "    k_fold = KFold(n_splits=5,shuffle = False)\n",
    "    results = []\n",
    "    models = []\n",
    "    ite = []\n",
    "    acc = []\n",
    "    pre = []\n",
    "    rec = []\n",
    "    num = []\n",
    "    num0 = len(train_X_o)\n",
    "    print(num)\n",
    "    for i in [10,100,200,300,400,500,600,700,800,900,num0]:\n",
    "        num.append(i)\n",
    "        train_X = train_X_o[:i]\n",
    "        train_y = train_y_o[:i]\n",
    "        models.append(BernoulliNB(alpha=0.2, binarize=0.0))\n",
    "        for i in range(len(models)):\n",
    "            lis = cross_validation(k_fold,models[i],train_X, train_y,max_feature,ngram_range)\n",
    "        acc.append(lis[0])\n",
    "        pre.append(lis[1])\n",
    "        rec.append(lis[2])\n",
    "    plt.figure()\n",
    "    plt.plot(num, acc)\n",
    "    plt.title('crossvalidation accuracy over train size')\n",
    "    plt.xlabel('size #')\n",
    "    plt.ylabel('accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(num, pre)\n",
    "    plt.title('precision over train size')\n",
    "    plt.xlabel('size #')\n",
    "    plt.ylabel('precision')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(num, rec)\n",
    "    plt.title('recall over train size')\n",
    "    plt.xlabel('size #')\n",
    "    plt.ylabel('recall')\n",
    "    \n",
    "    plt.show()\n",
    "    # return results_df\n",
    "# train_models(X_train, y_train,1000,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-89f604ecef69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'MODEL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Recall'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtrain_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-61-89f604ecef69>\u001b[0m in \u001b[0;36mtrain_models\u001b[1;34m(train_X, train_y, max_feature, ngram_range)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mlis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodels_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-56c69900f58e>\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(k_fold, clf, X, y, max_feature, ngram_range)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0maccuracy_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mprecision_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mrecall_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "def train_models(train_X, train_y,max_feature,ngram_range):\n",
    "    k_fold = KFold(n_splits=5,shuffle = False)\n",
    "    results = []\n",
    "    models = []\n",
    "    models.append(SVR(C=1.0, epsilon=0.2))\n",
    "    models.append(SVR(C=1.0, epsilon=0.2))\n",
    "    models_name = ['SVR(gamma=scale, C=1.0, epsilon=0.2)','SVR(gamma=scale, C=1.0, epsilon=0.2)']\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        print(i)\n",
    "        lis = cross_validation(k_fold,models[i],train_X, train_y,max_feature,ngram_range)\n",
    "        results.append([models_name[i],lis[0],lis[1],lis[2]])\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.columns = ['MODEL', 'Accuracy','Precision','Recall']\n",
    "    return results_df\n",
    "train_models(X_train, y_train,1000,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "4_9_Original.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
